{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing Indian Market Data for Machine Learning Trading Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to adapt the machine learning for trading techniques in this repository for Indian stock markets. We'll show how to download data for Indian stocks and apply the same feature engineering and modeling approaches used throughout the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Installation\n",
    "\n",
    "**Note:** Before running this notebook, ensure you have the required packages installed:\n",
    "\n",
    "```bash\n",
    "pip install yfinance pandas numpy matplotlib seaborn scikit-learn\n",
    "```\n",
    "\n",
    "If you're using the conda environment from this repository's installation instructions, these packages should already be available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Stock Universe\n",
    "\n",
    "Let's define a universe of popular Indian stocks from different sectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Popular Indian stocks with NSE symbols\n",
    "indian_stocks = {\n",
    "    # Technology\n",
    "    'TCS.NS': 'Tata Consultancy Services',\n",
    "    'INFY.NS': 'Infosys',\n",
    "    'WIPRO.NS': 'Wipro',\n",
    "    'TECHM.NS': 'Tech Mahindra',\n",
    "    \n",
    "    # Financial Services\n",
    "    'HDFCBANK.NS': 'HDFC Bank',\n",
    "    'ICICIBANK.NS': 'ICICI Bank',\n",
    "    'SBIN.NS': 'State Bank of India',\n",
    "    'KOTAKBANK.NS': 'Kotak Mahindra Bank',\n",
    "    \n",
    "    # Energy & Oil\n",
    "    'RELIANCE.NS': 'Reliance Industries',\n",
    "    'ONGC.NS': 'Oil and Natural Gas Corporation',\n",
    "    'BPCL.NS': 'Bharat Petroleum',\n",
    "    \n",
    "    # Pharmaceuticals\n",
    "    'SUNPHARMA.NS': 'Sun Pharmaceutical',\n",
    "    'DRREDDY.NS': 'Dr. Reddy\\'s Laboratories',\n",
    "    'CIPLA.NS': 'Cipla',\n",
    "    \n",
    "    # Consumer Goods\n",
    "    'HINDUNILVR.NS': 'Hindustan Unilever',\n",
    "    'ITC.NS': 'ITC Limited',\n",
    "    'NESTLEIND.NS': 'Nestle India',\n",
    "    \n",
    "    # Automotive\n",
    "    'MARUTI.NS': 'Maruti Suzuki',\n",
    "    'TATAMOTORS.NS': 'Tata Motors',\n",
    "    'M&M.NS': 'Mahindra & Mahindra'\n",
    "}\n",
    "\n",
    "symbols = list(indian_stocks.keys())\n",
    "print(f\"Indian stock universe: {len(symbols)} stocks\")\n",
    "for symbol, name in list(indian_stocks.items())[:5]:\n",
    "    print(f\"{symbol}: {name}\")\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Indian Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for historical data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=365*2)  # 2 years of data\n",
    "\n",
    "print(f\"Downloading data from {start_date.date()} to {end_date.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for all Indian stocks\n",
    "data = yf.download(symbols, start=start_date, end=end_date, progress=True)\n",
    "\n",
    "print(f\"Downloaded data shape: {data.shape}\")\n",
    "print(f\"Date range: {data.index[0]} to {data.index[-1]}\")\n",
    "print(f\"Columns: {data.columns.names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "print(\"Data availability by stock:\")\n",
    "availability = data['Close'].count().sort_values(ascending=False)\n",
    "print(availability.head(10))\n",
    "\n",
    "# Plot data availability\n",
    "plt.figure(figsize=(12, 6))\n",
    "availability.plot(kind='bar')\n",
    "plt.title('Data Availability by Stock (Number of Trading Days)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Index Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download major Indian market indices\n",
    "indices = {\n",
    "    '^NSEI': 'NIFTY 50',\n",
    "    '^BSESN': 'SENSEX',\n",
    "    '^NSEBANK': 'NIFTY BANK'\n",
    "}\n",
    "\n",
    "index_data = yf.download(list(indices.keys()), start=start_date, end=end_date)\n",
    "\n",
    "# Plot major indices\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, (symbol, name) in enumerate(indices.items()):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    index_prices = index_data['Close'][symbol].dropna()\n",
    "    plt.plot(index_prices.index, index_prices.values)\n",
    "    plt.title(f'{name} ({symbol})')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering for Indian Stocks\n",
    "\n",
    "Now we'll apply the same feature engineering techniques used throughout the book to Indian stock data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on a few liquid stocks for feature engineering\n",
    "liquid_stocks = ['RELIANCE.NS', 'TCS.NS', 'HDFCBANK.NS', 'INFY.NS', 'ITC.NS']\n",
    "\n",
    "# Extract OHLCV data\n",
    "ohlcv_data = {}\n",
    "for stock in liquid_stocks:\n",
    "    stock_data = pd.DataFrame()\n",
    "    stock_data['open'] = data['Open'][stock]\n",
    "    stock_data['high'] = data['High'][stock]\n",
    "    stock_data['low'] = data['Low'][stock]\n",
    "    stock_data['close'] = data['Close'][stock]\n",
    "    stock_data['volume'] = data['Volume'][stock]\n",
    "    \n",
    "    # Remove any rows with missing data\n",
    "    stock_data = stock_data.dropna()\n",
    "    ohlcv_data[stock] = stock_data\n",
    "\n",
    "print(f\"Prepared OHLCV data for {len(liquid_stocks)} stocks\")\n",
    "print(f\"Sample data shape for {liquid_stocks[0]}: {ohlcv_data[liquid_stocks[0]].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_features(df):\n",
    "    \"\"\"Calculate technical indicators for Indian stocks\"\"\"\n",
    "    result = df.copy()\n",
    "    \n",
    "    # Price-based features\n",
    "    result['returns'] = df['close'].pct_change()\n",
    "    result['log_returns'] = np.log(df['close'] / df['close'].shift(1))\n",
    "    \n",
    "    # Moving averages\n",
    "    result['sma_5'] = df['close'].rolling(5).mean()\n",
    "    result['sma_20'] = df['close'].rolling(20).mean()\n",
    "    result['sma_50'] = df['close'].rolling(50).mean()\n",
    "    \n",
    "    # Price ratios\n",
    "    result['price_to_sma20'] = df['close'] / result['sma_20']\n",
    "    result['sma5_to_sma20'] = result['sma_5'] / result['sma_20']\n",
    "    \n",
    "    # Volatility\n",
    "    result['volatility_20'] = result['returns'].rolling(20).std()\n",
    "    \n",
    "    # Volume features\n",
    "    result['volume_ma_20'] = df['volume'].rolling(20).mean()\n",
    "    result['volume_ratio'] = df['volume'] / result['volume_ma_20']\n",
    "    \n",
    "    # Price range features\n",
    "    result['high_low_ratio'] = df['high'] / df['low']\n",
    "    result['close_to_high'] = df['close'] / df['high']\n",
    "    result['close_to_low'] = df['close'] / df['low']\n",
    "    \n",
    "    # Momentum indicators\n",
    "    result['rsi'] = calculate_rsi(df['close'], 14)\n",
    "    result['momentum_10'] = df['close'] / df['close'].shift(10) - 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_rsi(prices, window=14):\n",
    "    \"\"\"Calculate Relative Strength Index\"\"\"\n",
    "    delta = prices.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate features for all liquid stocks\n",
    "enhanced_data = {}\n",
    "for stock in liquid_stocks:\n",
    "    enhanced_data[stock] = calculate_technical_features(ohlcv_data[stock])\n",
    "    print(f\"Features calculated for {stock}: {enhanced_data[stock].shape[1]} features\")\n",
    "\n",
    "# Display sample features for one stock\n",
    "sample_stock = liquid_stocks[0]\n",
    "print(f\"\\nSample features for {sample_stock}:\")\n",
    "print(enhanced_data[sample_stock].columns.tolist())\n",
    "print(f\"\\nLast 5 rows of data:\")\n",
    "print(enhanced_data[sample_stock][['close', 'returns', 'sma_20', 'rsi', 'volatility_20']].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Analysis: Indian Stock Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze correlation between stocks\n",
    "returns_data = pd.DataFrame()\n",
    "for stock in liquid_stocks:\n",
    "    returns_data[stock] = enhanced_data[stock]['returns']\n",
    "\n",
    "correlation_matrix = returns_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "           square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix: Indian Stock Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Average correlation between stocks:\", correlation_matrix.values[np.triu_indices_from(correlation_matrix.values, k=1)].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare volatility patterns\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, stock in enumerate(liquid_stocks):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    volatility = enhanced_data[stock]['volatility_20'].dropna()\n",
    "    plt.plot(volatility.index, volatility.values)\n",
    "    plt.title(f'20-day Rolling Volatility: {stock}')\n",
    "    plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Machine Learning\n",
    "\n",
    "Now we'll prepare the data in the same format used throughout the book for ML models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_ml_dataset(stock_data_dict, target_days=5):\n",
    "    \"\"\"Prepare dataset for ML prediction of Indian stocks\"\"\"\n",
    "    ml_data = []\n",
    "    \n",
    "    for stock_symbol, data in stock_data_dict.items():\n",
    "        # Calculate forward returns as target\n",
    "        data = data.copy()\n",
    "        data['target'] = data['close'].shift(-target_days) / data['close'] - 1\n",
    "        data['symbol'] = stock_symbol.replace('.NS', '')  # Clean symbol name\n",
    "        \n",
    "        # Select features (exclude non-numeric and target-related columns)\n",
    "        feature_cols = ['returns', 'sma_5', 'sma_20', 'sma_50', 'price_to_sma20', \n",
    "                       'sma5_to_sma20', 'volatility_20', 'volume_ratio', 'high_low_ratio',\n",
    "                       'close_to_high', 'close_to_low', 'rsi', 'momentum_10']\n",
    "        \n",
    "        # Create feature dataframe\n",
    "        features = data[feature_cols + ['target', 'symbol']].dropna()\n",
    "        features['date'] = features.index\n",
    "        \n",
    "        ml_data.append(features)\n",
    "    \n",
    "    # Combine all stocks\n",
    "    combined_data = pd.concat(ml_data, ignore_index=True)\n",
    "    return combined_data\n",
    "\n",
    "# Prepare ML dataset\n",
    "ml_dataset = prepare_ml_dataset(enhanced_data, target_days=5)\n",
    "print(f\"ML dataset shape: {ml_dataset.shape}\")\n",
    "print(f\"Features: {[col for col in ml_dataset.columns if col not in ['target', 'symbol', 'date']]}\")\n",
    "print(f\"\\nTarget distribution (5-day forward returns):\")\n",
    "print(ml_dataset['target'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "ml_dataset['target'].hist(bins=50, alpha=0.7)\n",
    "plt.title('Distribution of 5-day Forward Returns')\n",
    "plt.xlabel('Returns')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "ml_dataset.boxplot(column='target', by='symbol', ax=plt.gca())\n",
    "plt.title('Forward Returns by Stock')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Machine Learning Application\n",
    "\n",
    "Here's a simple example of how to apply the ML techniques from the book to Indian stock data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Prepare features and target\n",
    "feature_cols = [col for col in ml_dataset.columns if col not in ['target', 'symbol', 'date']]\n",
    "X = ml_dataset[feature_cols]\n",
    "y = ml_dataset['target']\n",
    "\n",
    "# Remove any remaining NaN values\n",
    "mask = ~(X.isna().any(axis=1) | y.isna())\n",
    "X_clean = X[mask]\n",
    "y_clean = y[mask]\n",
    "\n",
    "print(f\"Clean dataset shape: {X_clean.shape}\")\n",
    "print(f\"Features used: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data chronologically (important for time series)\n",
    "# Use first 80% for training, last 20% for testing\n",
    "split_idx = int(0.8 * len(X_clean))\n",
    "X_train, X_test = X_clean.iloc[:split_idx], X_clean.iloc[split_idx:]\n",
    "y_train, y_test = y_clean.iloc[:split_idx], y_clean.iloc[split_idx:]\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"\\nModel Performance on Indian Stocks:\")\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"MAE: {mae:.4f}\")\n",
    "print(f\"Mean absolute actual return: {np.abs(y_test).mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
    "plt.title('Feature Importance for Indian Stock Prediction')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 most important features:\")\n",
    "print(feature_importance.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction vs actual scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.6)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Returns')\n",
    "plt.ylabel('Predicted Returns')\n",
    "plt.title('Prediction vs Actual: Indian Stock Returns')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation between predictions and actual\n",
    "correlation = np.corrcoef(y_test, y_pred)[0, 1]\n",
    "print(f\"Correlation between predicted and actual returns: {correlation:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Indian Market Trading Strategies\n",
    "\n",
    "This notebook demonstrates the basic adaptation of ML4T techniques to Indian markets. To build a complete trading strategy, consider:\n",
    "\n",
    "### 1. Enhanced Feature Engineering\n",
    "- **Sector-specific features**: Indian market sectors (IT, Pharma, Banking) have unique characteristics\n",
    "- **Macro indicators**: Include Indian economic indicators (repo rate, inflation, etc.)\n",
    "- **Currency features**: USD/INR exchange rate affects export-heavy stocks\n",
    "\n",
    "### 2. Indian Market-Specific Considerations\n",
    "- **Impact cost**: Higher for smaller caps compared to US markets\n",
    "- **Settlement & clearing**: T+2 settlement cycle\n",
    "- **Market timing**: IST 9:15 AM - 3:30 PM trading window\n",
    "- **Regulatory framework**: SEBI regulations and disclosure requirements\n",
    "\n",
    "### 3. Advanced Data Sources\n",
    "- **Corporate actions**: Bonus issues, stock splits, dividends\n",
    "- **Fundamental data**: Annual reports, quarterly results\n",
    "- **Alternative data**: News sentiment in Hindi/English, satellite data for infrastructure companies\n",
    "\n",
    "### 4. Strategy Implementation\n",
    "- **Backtesting**: Adapt Zipline or use Indian market backtesting frameworks\n",
    "- **Execution**: Connect to Indian brokers' APIs (Zerodha, Angel Broking, etc.)\n",
    "- **Risk management**: Consider Indian market-specific risks\n",
    "\n",
    "### 5. Resources for Further Development\n",
    "- **NSE/BSE historical data**: Official exchange data\n",
    "- **Indian broker APIs**: Zerodha Kite, Angel Broking, etc.\n",
    "- **Economic data**: RBI, Ministry of Statistics data\n",
    "- **News sources**: Economic Times, Business Standard APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data for further analysis\n",
    "# ml_dataset.to_csv('indian_stocks_ml_dataset.csv', index=False)\n",
    "# print(\"Dataset saved as 'indian_stocks_ml_dataset.csv'\")\n",
    "\n",
    "print(\"\\n=== Summary ===\")\n",
    "print(f\"Successfully processed {len(liquid_stocks)} Indian stocks\")\n",
    "print(f\"Generated {len(feature_cols)} technical features\")\n",
    "print(f\"Built ML model with {correlation:.3f} prediction correlation\")\n",
    "print(\"\\nThe techniques from this book can be successfully adapted for Indian markets!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}